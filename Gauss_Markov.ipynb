{
 "metadata": {
  "name": "Gauss_Markov"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Introduction\n",
      "-------------------\n",
      "\n",
      "In this section, we will consider the famous Gauss-Markov problem. Now, we have all the techniques we need to understand this.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the following problem:\n",
      "\n",
      "$$ \\mathbf{y} = \\mathbf{W} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} $$\n",
      "\n",
      "where $\\mathbf{W}$ is a $ n \\times m $ matrix, and $\\mathbf{y}$ is a $n \\times 1$ vector. Also, $\\boldsymbol{\\epsilon}$ is a random vector with zero-mean and \n",
      "\n",
      "$$ \\mathbb{E}( \\boldsymbol{\\epsilon} \\boldsymbol{\\epsilon}^T) = \\mathbf{Q}$$\n",
      "\n",
      "The problem is to find $\\mathbf{K}$ so that $ \\boldsymbol{\\hat{\\beta}} = \\mathbf{K} \\mathbf{y}$ that approximates $ \\boldsymbol{\\beta}$.\n",
      "\n",
      "We can approach this problem the usual way by trying to solve the MMSE problem:\n",
      "\n",
      "$$ \\min_K \\mathbf{E}(|| \\boldsymbol{\\hat{\\beta}}- \\boldsymbol{\\beta} ||^2)$$\n",
      "\n",
      "which we can write out as\n",
      "\n",
      "$$  \\min_K \\mathbf{E}(|| \\mathbf{K W} \\boldsymbol{\\beta} -  \\boldsymbol{\\beta}||^2) + Trace(\\mathbf{K Q K}^T) $$\n",
      "\n",
      "Now, if we were to solve this for $\\mathbf{K}$, it would be a function of $ \\boldsymbol{\\beta}$, which is the same thing as saying that the estimator, $ \\boldsymbol{\\hat{\\beta}}$, is a function of what we are trying to estimate, $ \\boldsymbol{\\beta}$, which makes no sense.\n",
      "\n",
      "However, writing this out tells us that if we had $\\mathbf{K W}= \\mathbf{I}$, then the first term would vanish and the problem simplifies to\n",
      "\n",
      "$$ \\min_K Trace(\\mathbf{K Q K}^T) $$\n",
      "\n",
      "with\n",
      "\n",
      "$$ \\mathbf{KW} = \\mathbf{I}$$\n",
      "\n",
      "This requirement is the same as asserting that the estimator is unbiased,\n",
      "\n",
      "$$ \\mathbb{E}( \\boldsymbol{\\hat{\\beta}}) = \\mathbf{KW}  \\boldsymbol{\\beta} =  \\boldsymbol{\\beta}  $$ \n",
      "\n",
      "To line this problem up with our earlier work, let's consider  the $i^{th}$ column of $\\mathbf{K}$, $\\mathbf{k}_i$. Now, we can re-write the problem as\n",
      "\n",
      "$$ \\min_k (\\mathbf{k_i^T Q k_i}) $$\n",
      "\n",
      "with\n",
      "\n",
      "$$ \\mathbf{k_i}^T \\mathbf{W} = \\mathbf{e}_i$$\n",
      "\n",
      "and from our previous work on contrained optimization, we know how to solve this:\n",
      "\n",
      "$$ \\mathbf{k}_i  = \\mathbf{Q}^{-1} \\mathbf{W}(\\mathbf{W}^T \\mathbf{Q^{-1} W})^{-1}\\mathbf{e}_i$$\n",
      "\n",
      "Now all we have to do is stack these together for the general solution:\n",
      "\n",
      "$$ \\mathbf{K}  = \\mathbf{Q}^{-1} \\mathbf{W}(\\mathbf{W}^T \\mathbf{Q^{-1} W})^{-1} $$\n",
      "\n",
      "It's easy when you have all of the concepts lined up!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using a simple example, we have emphasized the connection between minimum mean squared error problems and conditional expectation. Next, we'll continue revealing  the true power of the conditional expectation as we continue to develop a corresponding geometric intuition.\n",
      "\n",
      "As usual, the corresponding ipython notebook for this post  is available for download [here](https://github.com/unpingco/Python-for-Signal-Processing/blob/master/Conditional_expectation_MSE.ipynb). \n",
      "\n",
      "Comments and corrections welcome!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "References\n",
      "---------------\n",
      "\n",
      "* Luenberger, David G. *Optimization by vector space methods*. Wiley-Interscience, 1997."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}