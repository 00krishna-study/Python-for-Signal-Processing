{
 "metadata": {
  "name": "Conditional_Expectation_Projection"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Proof that $\\mathbb{E}(x|y)$ is Minimum MSE solution\n",
      "\n",
      "$$ $$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ \\min_h \\int_\\mathbb{R^2} | X - h(Y) |^2 f_{x,y}(X,Y) dx dy $$\n",
      "\n",
      "$$ \\min_h \\int_\\mathbb{R^2} | X |^2 f_{x,y}(X,Y) dx dy + \\int_\\mathbb{R^2} | h(Y) |^2 f_{x,y}(X,Y) dx dy - \\int_\\mathbb{R^2} 2 X h(Y) f_{x,y}(X,Y) dx dy $$\n",
      "\n",
      "Now, we want to maximize the following:\n",
      "\n",
      "$$ \\max_h \\int_\\mathbb{R^2}  X h(Y) f_{x,y}(X,Y) dx dy  $$ \n",
      "\n",
      "Breaking up the integral using the definition of conditional expectation\n",
      "\n",
      "$$ \\max_h \\int_\\mathbb{R}   \\left(\\int_\\mathbb{R} X  f_{x|y}(X|Y) dx \\right)h(Y) f_Y(Y)   dy  $$ \n",
      "\n",
      "$$ \\max_h \\int_\\mathbb{R} \\mathbb{E}(X|Y) h(Y)f_Y(Y)   dy  $$ \n",
      "\n",
      "From properties of the Cauchy-Schwarz inequality, we know that the maximum happens when $h(Y) = \\mathbb{E}(X|Y)$, so we have found the optimal $h(Y)$ function as :\n",
      "\n",
      "$$ h(Y) = \\mathbb{E}(X|Y)$$ \n",
      "\n",
      "which shows that the optimal function is the conditional expectation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we have a random variable, $X$, then what constant is closest to $X$ in the mean-squared-sense (MSE)? In other words, which $c$ minimizes the following:\n",
      "\n",
      "$$ J = \\mathbb{E}( X - c )^2 $$ \n",
      "\n",
      "we can work this out as\n",
      "\n",
      "$$ \\mathbb{E}( X - c )^2 = \\mathbb{E}(c^2 - 2 c X + X^2)  $$ \n",
      "\n",
      "and then take the first derivative with respect to $c$ and solve:\n",
      "\n",
      "$$ c=\\mathbb{E}(X) $$ \n",
      "\n",
      "Remember that $X$ can take on all kinds of values, but this says that the closest number to $X$ in the MSE sense is $\\mathbb{E}(X)$.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's continue our discussion of the conditional expectation operator by connecting it to the concept of projection. \n",
      "\n",
      "In the figure below, I want to find a point along the blue line that is closest to the red square. In other words, I want to inflate the pink circle until it just touches the blue line. Then, that point will be the closest point on the blue line to the red square."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It may be geometrically obvious, but the closest point on the line occurs where the line from the red square to the line is perpedicular to the line. At this point, the pink circle just touches the blue line."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is an arbitrary point along the blue line:\n",
      "\n",
      "$$ \\mathbf{x} = \\alpha \\mathbf{v} $$ \n",
      "\n",
      "where \n",
      "\n",
      "$$ \\mathbf{v} = \\left[ \\begin{array}{c}\n",
      "1 \\\\\n",
      "1 \\\\\n",
      "\\end{array} \\right] $$ \n",
      "\n",
      "so that $\\alpha$ slides the point up and down the line. At the closest point, the vector between $\\mathbf{y}$ and $\\mathbf{x}$ (the dotted green line above) is perpedicular to the line. This means that\n",
      "\n",
      "$$ ( \\mathbf{y}-\\mathbf{x} )^T \\mathbf{v} = 0$$ \n",
      "\n",
      "and by substituting and working out the terms gives \n",
      "\n",
      "$$ \\alpha = \\frac{\\mathbf{y}^T\\mathbf{v}}{|\\mathbf{v}|^2}  = \\frac{1}{2} ( y_0 + y_1 )$$\n",
      "\n",
      "Using the Pythagorean theorem, we compute the squared length of the error as\n",
      "\n",
      "$$ \\epsilon^2 = |( \\mathbf{y}-\\mathbf{x} )|^2 = |\\mathbf{y}|^2 - \\alpha^2 |\\mathbf{v}|^2 = |\\mathbf{y}|^2 - \\frac{|\\mathbf{y}^T\\mathbf{v}|^2}{|\\mathbf{v}|^2}  $$\n",
      "\n",
      "where $ |\\mathbf{v}|^2 = \\mathbf{v}^T \\mathbf{v} $. Note that since $\\epsilon^2 \\ge 0 $, this also shows that\n",
      "\n",
      "$$ |\\mathbf{y}^T\\mathbf{v}| \\le |\\mathbf{y}|  |\\mathbf{v}|   $$ \n",
      "\n",
      "which is the famous Cauchy-Schwarz inequality. This inequality will soon be very important  for us.\n",
      "\n",
      "Finally, we can assemble all of this into the *projection* operator\n",
      "\n",
      "$$ \\mathbf{P}_v = \\frac{1}{|\\mathbf{v}|^2 } \\mathbf{v v}^T $$\n",
      "\n",
      "With this operator, we can take any given $\\mathbf{y}$ and project it onto $\\mathbf{v}$ by doing\n",
      "\n",
      "$$ \\mathbf{P}_v \\mathbf{y} $$ \n",
      "\n",
      "It's called an operator because it takes a vector and produces another vector.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}